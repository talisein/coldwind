  * Save by original filename [Easy] 
      (The filename is already parsed and saved into Image.  All you
    need to do is open glade, modify the UI so there's a checkbox
    somewhere and hook it up in application.?xx, add a field to
    Request, and modify Downloader's interface to accept requests
    rather than just the directory pointer)

  * Lurker should use a std::set rather than std::list [Easy] (Just
    make sure you test this)

  * Record download statistics from curl (Time, Bytes), populate back
    to UI [Medium] [Mostly done]

  * Decode curl's error messages and put on std:cerr [Easy] [Mostly
    done]

  * Redirect std::cout and std::cerr to an optional popup message log
    [Hard] (There's actually a Glib API for this)

  * The parser should recognize 404s, and the Lurker should drop it
    [Medium]

  * Capture libxml errors and do the right thing. [Easy/Medium?]

  * Overlay some lurker info text on the image [Medium]
  ** Or some sort of visual lurker feedback. I dunno. [Hard]

  * The hasher shouldn't try to hash anything larger than 4chan's
    maximum image size [Easy]

  * The gif animation isn't smooth anymore during downloads. So we
    should do all our Downloader work in a worker thread. This should
    involve storing a Glib::Thread reference and join()ing it before
    spinning up a new one. Also might want a mutex around m_mcurl just
    to be sure. In fact, we need one for sure (While adding curl
    handles in the initial kickstart, we might get a timeout callback)
    [Hard]

  * Store a cache of CURL*s in Downloader rather than creating new
    ones every time.

  * Create a thread subdirectory option. Maybe a board too.